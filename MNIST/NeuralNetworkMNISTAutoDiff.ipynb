{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Neural Network with Autograd\n",
    "<br\\>\n",
    "This notebook implements a Neural Network for recognizing hand written digits, trained using the MNIST database. The backpropagation algorithm is <b>not</b> implemented explicitly. Instead, we build the computational graph associated with the network and calculate the gradients via reverse mode differentiation. We carry out these calculations with the help of `pytorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "import timeit\n",
    "import torch\n",
    "from torch import Tensor, LongTensor\n",
    "from torch.autograd import Variable\n",
    "import line_profiler\n",
    "%load_ext line_profiler\n",
    "\n",
    "dtype_float = torch.FloatTensor\n",
    "dtype_int   = torch.IntTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkMNISTAutoGrad(object):\n",
    "    \"\"\"\n",
    "    A Neural Network designed to be used with the MNIST database. \n",
    "    Gradients are calculated using reverse mode differentiation on\n",
    "    the computational graphs associated with the network.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layersz):\n",
    "        \"\"\"\n",
    "        Pass in a list of layer sizes (layersz[0]/layersz[-1] are the input/output layers).\n",
    "        The size of this list is the number of layers in the network.\n",
    "        Since we are using this network with the MNIST database, the input layer must\n",
    "        be of size 784 = 28 x 28 (the number of pixels of each image). Also, the ouput\n",
    "        layer must be of size 10 (to represent 0...9).\n",
    "        \n",
    "        PARAMETERS:\n",
    "        layersz -- list of layer sizes    \n",
    "        \"\"\"\n",
    "        if layersz [0] != 784: raise RuntimeError('The size of the input layer must be 784')\n",
    "        if layersz[-1] !=  10: raise RuntimeError('The size of the output layer must be 10')\n",
    "        \n",
    "        self.nlayers = len(layersz)\n",
    "        self.layersz = layersz\n",
    "\n",
    "        # Initializes biases and weights with random values from a N(0,1) distribution.\n",
    "        # The following convention is used for weights: \n",
    "        #    w[i,j] denotes the weight associated with the connection from neuron\n",
    "        #   'j' in the previous layer to the neuron 'i' in the current layer.\n",
    "                \n",
    "        # NOTE: we use the numpy random number generator as opposed to the pytorch one,\n",
    "        #       so we can compare with other implementations, for debugging\n",
    "        bs = [np.random.randn(i, 1) for i in layersz[1:]]\n",
    "        ws = [np.random.randn(i, j) for i, j in zip(layersz[1:], layersz[:-1])]\n",
    "\n",
    "        self.biases  = [Variable(torch.from_numpy(b).type(dtype_float), requires_grad=True) for b in bs]\n",
    "        self.weights = [Variable(torch.from_numpy(w).type(dtype_float), requires_grad=True) for w in ws]\n",
    "\n",
    "        \n",
    "    def feedforward(self, a):\n",
    "        \"\"\"\n",
    "        Propagates a given input vector forward through the network and returns the output.\n",
    "        PARAMETERS:\n",
    "        a Variable/Tensor of size [784, 1], representing a digit image from the MNIST database\n",
    "        RETURN:\n",
    "        a Variable/Tensor of size [10, 1], a one-hot representation of the network output (0..9)       \n",
    "        \"\"\"        \n",
    "        if a.data.shape != (self.layersz[0], 1):\n",
    "            raise RuntimeError('Input array has wrong shape - must be (784, 1)')\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = torch.sigmoid(torch.mm(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    def SGD(self, training_data, epochs, batchsz, eta, test_data=None):\n",
    "        \"\"\"\n",
    "        Train the neural network using batch stochastic gradient descent.  \n",
    "        The network weights and biases are updated as the result of running this method.\n",
    "        Both 'training_data' and 'test_data' are lists of tuples, each tuple being an\n",
    "        example - the first element is the network input, the second is the target output.\n",
    "        For both data sets, the first tuple element is an MNIST digit image, represented \n",
    "        as a Variable/Tensor of size [784, 1].\n",
    "        The target output (the digit associated with the image) is represented as a one-hot\n",
    "        Variable/Tensor of size [10, 1] in 'training_data', and as the actual digit (0..9) in \n",
    "        'test_data'.\n",
    "        \n",
    "        PARAMETERS:\n",
    "        training_data -- list of tuples representing training inputs and the desired outputs  \n",
    "        epochs        -- for how many epochs to train the network\n",
    "        batchsz       -- the size of each batch of training example (this is *stochastic* GD)\n",
    "        eta           -- the learning rate\n",
    "        test_data     -- used to evaluate the performace of the network at the end of each epoch\n",
    "        \"\"\"\n",
    "        for j in range(epochs):\n",
    "            start_time = timeit.default_timer()\n",
    "                \n",
    "            # break up the training data into batches\n",
    "            np.random.shuffle(training_data)\n",
    "            batches = [training_data[k:k+batchsz] for k in range(0, len(training_data), batchsz)]\n",
    "            \n",
    "            # SGD means that we update weights/biases based on gradients calculated\n",
    "            # using only a batch of training examples (as opposed to the entire training data) \n",
    "            for batch in batches:\n",
    "                                \n",
    "                # calculate the (stochastic) gradient\n",
    "                # below 'x' represents an input image, 'y' the associated digit\n",
    "                for x, y in batch:\n",
    "                    out  = self.feedforward(x)\n",
    "                    loss = (out - y).pow(2).sum()  # <-- quadratic loss function\n",
    "                    loss.backward()\n",
    "                        \n",
    "                # update weights/biases in the direction of the stochastic gradient\n",
    "                eta_scaled = float(eta)/len(batch)\n",
    "                for w in self.weights: w.data -= eta_scaled * w.grad.data\n",
    "                for b in self.biases:  b.data -= eta_scaled * b.grad.data\n",
    "                \n",
    "                for b in self.biases:  b.grad.data.zero_() \n",
    "                for w in self.weights: w.grad.data.zero_() \n",
    "                \n",
    "            dt = timeit.default_timer() - start_time\n",
    "            if test_data: print(\"Epoch %2d: %d of %d (elapsed time: %fs)\" % (j+1, self.evaluate(test_data), len(test_data), dt))\n",
    "            else:         print(\"Epoch %2d complete  (elapsed time: %fs)\" % (j+1), dt)\n",
    "\n",
    "                \n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"\n",
    "        Evaluates the performance of the neural network on a given data set.\n",
    "        This dataset consists of a list of tuples, each tuple being an example: \n",
    "        the first tuple entry is an image encoded as an is a Variable/Tensor of \n",
    "        size [784, 1] the second one is a Variable storing the digit the image\n",
    "        represents (as 0..9). \n",
    "        PARAMETERS:\n",
    "        test_data -- dataset used for evaluating network performance\n",
    "        RETURNS:\n",
    "        number of correct answers on the given dataset\n",
    "        \"\"\"\n",
    "        # when passing an image through the network, the output is a one-hot vector\n",
    "        # we use the 'argmax' to convert this vector to the 0..9 digit it represents        \n",
    "        test_results = [(np.argmax(self.feedforward(x).data.numpy()), y) for (x, y) in test_data]        \n",
    "        return sum(int(x == y.data[0]) for (x, y) in test_results)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the MNIST database...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# where to find the file storing the MNIST database\n",
    "MNIST_DATA_FILEPATH = \"mnist.pkl.gz\"\n",
    "\n",
    "def load_data_raw():\n",
    "    \"\"\"\n",
    "    Return the MNIST data as a tuple containing the training data,\n",
    "    the validation data, and the test data.\n",
    "\n",
    "    The 'training_data' is returned as a tuple with two entries.\n",
    "    The first entry contains the actual training images.  This is a\n",
    "    numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n",
    "    numpy ndarray with 784 values, representing the 28 * 28 = 784\n",
    "    pixels in a single MNIST image.\n",
    "\n",
    "    The second entry in the 'training_data' tuple is a numpy ndarray\n",
    "    containing 50,000 entries.  Those entries are just the digit\n",
    "    values (0...9) for the corresponding images contained in the first\n",
    "    entry of the tuple.\n",
    "\n",
    "    The 'validation_data' and 'test_data' are similar, except\n",
    "    each contains only 10,000 images.\n",
    "    \"\"\"\n",
    "    f = gzip.open(MNIST_DATA_FILEPATH, 'rb')\n",
    "    training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Repackages the data returned by 'load_data_raw' in a format\n",
    "    more convenient for using with the neural network.\n",
    "    \n",
    "    Return a tuple (training_data, validation_data, test_data).\n",
    "\n",
    "    'training_data'   is a list of 50,000 2-tuples (x, y)\n",
    "    'validation_data' is a list of 10,000 2-tuples (x, z)\n",
    "    'test_data'       is a list of 10,000 2-tuples (x, z)\n",
    "\n",
    "    'x' is a Variable/Tensor of size [784, 1] containing the input image.\n",
    "    'y' is a Variable/Tensor of size [ 10, 1] representing the digit encoded\n",
    "        by 'x' (it has 0 entries with the exception of one 1 in the position\n",
    "        of the digit represented by 'x')\n",
    "    'z' is a Variable storing just the digit represented by 'x'\n",
    "    \"\"\"\n",
    "    tr_d, va_d, te_d = load_data_raw()\n",
    "    \n",
    "    training_in = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "    training_in = [Variable(torch.from_numpy(x).type(dtype_float), requires_grad=False) for x in training_in]\n",
    "    \n",
    "    training_out = [asvector(y) for y in tr_d[1]]\n",
    "    training_out = [Variable(torch.from_numpy(y).type(dtype_float), requires_grad=False) for y in training_out]\n",
    "\n",
    "    training_data = zip(training_in, training_out)\n",
    "\n",
    "    # ------------\n",
    "    \n",
    "    validation_in = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "    validation_in = [Variable(torch.from_numpy(x).type(dtype_float), requires_grad=False) for x in validation_in]  \n",
    "\n",
    "    validation_out  = [Variable(torch.from_numpy(np.array([y])).type(dtype_float), requires_grad=False) for y in va_d[1]]\n",
    "    validation_data = zip(validation_in, validation_out)\n",
    "\n",
    "    # ------------\n",
    "\n",
    "    test_in = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "    test_in = [Variable(torch.from_numpy(x).type(dtype_float), requires_grad=False) for x in test_in]\n",
    "\n",
    "    test_out  = [Variable(torch.from_numpy(np.array([y])).type(dtype_float), requires_grad=False) for y in te_d[1]]\n",
    "    test_data = zip(test_in, test_out)\n",
    "\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "\n",
    "def asvector(j):\n",
    "    \"\"\"Create vector of shape (10, 1) with 1.0 in the jth position and 0.0 elsewhere.\"\"\"\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e\n",
    "\n",
    "# load the MNIST database\n",
    "print(\"Loading the MNIST database...\")\n",
    "training_data, validation_data, test_data = [list(d) for d in load_data()]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a Neural Network\n",
    "\n",
    "layer_sizes = [784, 30, 10]  # <-- first entry must be 784, last one must be 10\n",
    "\n",
    "np.random.seed(1234)\n",
    "net = NeuralNetworkMNISTAutoGrad(layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained network: got right 988 out of 10000 (accuracy 9.88 pct)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance of the untrained network\n",
    "\n",
    "nright = net.evaluate(test_data)\n",
    "print(\"Untrained network: got right %d out of %d (accuracy %.2f pct)\" % (nright, len(test_data), 100*float(nright)/len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: 9052 of 10000 (elapsed time: 35.017382s)\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "\n",
    "EPOCHS  = 10\n",
    "BATCHSZ = 10\n",
    "ETA     =  2\n",
    "\n",
    "net.SGD(training_data, EPOCHS, BATCHSZ, ETA, test_data=test_data)\n",
    "\n",
    "# to profile the network, run the line below instead of the one above\n",
    "# set EPOCHS = 1\n",
    "#%lprun -f net.SGD net.SGD(training_data, EPOCHS, BATCHSZ, ETA, test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
